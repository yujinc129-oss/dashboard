import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import ast
import matplotlib
import matplotlib.font_manager as fm
import platform, os
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression
import plotly.express as px

if st.session_state.get("font_cache_cleared") is not True:
    import shutil
    cache_dir = matplotlib.get_cachedir()
    shutil.rmtree(cache_dir, ignore_errors=True)
    st.session_state["font_cache_cleared"] = True

def set_korean_font():
    matplotlib.rcParams['axes.unicode_minus'] = False

    # 1) í”„ë¡œì íŠ¸ì— í¬í•¨í•œ í°íŠ¸(ê¶Œì¥) - íŒŒì¼ì„ ì—¬ê¸°ì— ë‘ì„¸ìš”: ./fonts/NanumGothic.ttf
    candidates = [
        os.path.join(os.path.dirname(__file__), "fonts", "NanumGothic.ttf"),
        os.path.join(os.getcwd(), "fonts", "NanumGothic.ttf"),
    ]

    # 2) Windows ê¸°ë³¸ í°íŠ¸ ê²½ë¡œë„ ì‹œë„
    if platform.system() == "Windows":
        candidates += [
            r"C:\Windows\Fonts\malgun.ttf",
            r"C:\Windows\Fonts\malgunbd.ttf",
        ]

    # 3) ì‹œìŠ¤í…œ í°íŠ¸ ê²€ìƒ‰(ë§ˆì§€ë§‰ í´ë°±)
    sys_fonts = fm.findSystemFonts(fontext="ttf")
    for f in sys_fonts:
        if any(k in f.lower() for k in ("nanum", "malgun", "applegothic", "notosanscjk", "gulim", "dotum", "batang")):
            candidates.append(f)

    # ë“±ë¡ ì‹œë„
    for path in candidates:
        if os.path.exists(path):
            try:
                fm.fontManager.addfont(path)  # í°íŠ¸ ë“±ë¡
                family = fm.FontProperties(fname=path).get_name()
                matplotlib.rcParams['font.family'] = family
                return family
            except Exception:
                pass
    return None

family = set_korean_font()
# ì„ íƒëœ í°íŠ¸ë¥¼ í™•ì¸í•˜ê³  ì‹¶ìœ¼ë©´:
# st.write("Using font:", family)

# =========================
# 0. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë° í´ë˜ìŠ¤
# =========================
class MultiLabelBinarizerTransformer(BaseEstimator, TransformerMixin):
    def __init__(self):
        self.mlb = MultiLabelBinarizer()
    def fit(self, X, y=None):
        lists = X.squeeze()
        self.mlb.fit(lists)
        return self
    def transform(self, X):
        lists = X.squeeze()
        return self.mlb.transform(lists)

def clean_cell(x):
    if isinstance(x, list):
        return x
    if pd.isna(x):
        return []
    if isinstance(x, str):
        try:
            parsed = ast.literal_eval(x)
            if isinstance(parsed, list):
                return parsed
        except:
            return [x.strip()]
    return [str(x)]

def safe_eval(val):
    if isinstance(val, list):
        return val
    if pd.isna(val):
        return []
    if isinstance(val, str):
        try:
            parsed = ast.literal_eval(val)
            if isinstance(parsed, list):
                return parsed
        except:
            pass
    return []

def flatten_list_str(x):
    if isinstance(x, list):
        return ','.join(map(str, x))
    if isinstance(x, str):
        try:
            parsed = ast.literal_eval(x)
            if isinstance(parsed, list):
                return ','.join(map(str, parsed))
        except:
            pass
    return str(x) if not pd.isna(x) else ''

def preprocess_ml_features(X: pd.DataFrame) -> pd.DataFrame:
    for col in ['ì¥ë¥´','í”Œë«í¼','ë°©ì˜ìš”ì¼']:
        if col in X.columns:
            X[col] = X[col].apply(safe_eval).apply(flatten_list_str)
    return X.fillna('')

# =========================
# 1. ë°ì´í„° ë¡œë“œ
# =========================
@st.cache_data
def load_data():
    raw = pd.read_json('drama_data.json')
    return pd.DataFrame({c: pd.Series(v) for c,v in raw.items()})

raw_df = load_data()              # EDAìš© ì›ë³¸
df      = raw_df.copy()           # MLìš© ë³µì‚¬ë³¸

# =========================
# 2. ë¨¸ì‹ ëŸ¬ë‹ìš© ì „ì²˜ë¦¬
# =========================
mlb_cols = ['ì¥ë¥´','í”Œë«í¼','ë°©ì˜ìš”ì¼']
for col in mlb_cols:
    df[col] = df[col].apply(clean_cell)
    mlb = MultiLabelBinarizer()
    arr = mlb.fit_transform(df[col])
    df = pd.concat([
        df,
        pd.DataFrame(arr, columns=[f"{col}_{c.upper()}" for c in mlb.classes_], index=df.index)
    ], axis=1)
#df.drop(columns=mlb_cols, inplace=True)

# =========================
# 3. EDAìš© ë¦¬ìŠ¤íŠ¸ í’€ê¸°
# =========================
genre_list       = [g for sub in raw_df['ì¥ë¥´'].dropna().apply(safe_eval) for g in sub]
broadcaster_list = [b for sub in raw_df['í”Œë«í¼'].dropna().apply(safe_eval) for b in sub]
week_list        = [w for sub in raw_df['ë°©ì˜ìš”ì¼'].dropna().apply(safe_eval) for w in sub]
unique_genres    = sorted(set(genre_list))

# =========================
# 4. Streamlit ë ˆì´ì•„ì›ƒ
# =========================
st.set_page_config(page_title="K-ë“œë¼ë§ˆ ë¶„ì„/ì˜ˆì¸¡", page_icon="ğŸ¬", layout="wide")
st.title("K-ë“œë¼ë§ˆ ë°ì´í„° ë¶„ì„ ë° ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")

# ì‚¬ì´ë“œë°”: ML íŒŒë¼ë¯¸í„° + ì˜ˆì¸¡ ì…ë ¥
with st.sidebar:
    st.header("ğŸ¤– ëª¨ë¸ ì„¤ì •")
    model_type   = st.selectbox('ëª¨ë¸ ì„ íƒ', ['Random Forest','Linear Regression'])
    test_size    = st.slider('í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨', 0.1,0.5,0.2,0.05)
    feature_cols = st.multiselect('íŠ¹ì„± ì„ íƒ',['ë‚˜ì´','ë°©ì˜ë…„ë„','ì„±ë³„','ì¥ë¥´','ë°°ìš°ëª…','í”Œë«í¼','ê²°í˜¼ì—¬ë¶€'], default=['ë‚˜ì´','ë°©ì˜ë…„ë„','ì¥ë¥´'])
    st.markdown("---")
    st.header("ğŸ¯ í‰ì  ì˜ˆì¸¡ ì…ë ¥")
    input_age     = st.number_input("ë°°ìš° ë‚˜ì´",10,80,30)
    input_year    = st.number_input("ë°©ì˜ë…„ë„",2000,2025,2021)
    input_gender  = st.selectbox("ì„±ë³„", sorted(raw_df['ì„±ë³„'].dropna().unique()))
    input_genre   = st.multiselect("ì¥ë¥´", unique_genres, default=unique_genres[:1])
    input_plat    = st.multiselect("í”Œë«í¼", sorted(set(broadcaster_list)), default=list({broadcaster_list[0]}))
    input_married = st.selectbox("ê²°í˜¼ì—¬ë¶€", sorted(raw_df['ê²°í˜¼ì—¬ë¶€'].dropna().unique()))
    predict_btn   = st.button("ì˜ˆì¸¡ ì‹¤í–‰")

# íƒ­ êµ¬ì„±
tabs = st.tabs(["ğŸ—‚ê°œìš”","ğŸ“Šê¸°ì´ˆí†µê³„","ğŸ“ˆë¶„í¬/êµì°¨","ğŸ’¬ì›Œë“œí´ë¼ìš°ë“œ","âš™ï¸í•„í„°","ğŸ”ì „ì²´ë³´ê¸°","ğŸ¤–MLëª¨ë¸","ğŸ”§íŠœë‹","ğŸ¯ì˜ˆì¸¡"])

# --- 4.1 ë°ì´í„° ê°œìš” ---
with tabs[0]:
    st.header("ë°ì´í„° ê°œìš”")
    c1,c2,c3 = st.columns(3)
    c1.metric("ìƒ˜í”Œ ìˆ˜", df.shape[0])
    c2.metric("ì»¬ëŸ¼ ìˆ˜", df.shape[1])
    c3.metric("ê³ ìœ  ì¥ë¥´", len(unique_genres))
    st.subheader("ê²°ì¸¡ì¹˜ ë¹„ìœ¨")
    st.dataframe(raw_df.isnull().mean())
    st.subheader("ì›ë³¸ ìƒ˜í”Œ")
    st.dataframe(raw_df.head(), use_container_width=True)

# --- 4.2 ê¸°ì´ˆí†µê³„ ---
with tabs[1]:
    st.header("ê¸°ì´ˆ í†µê³„: ì ìˆ˜")
    st.write(raw_df['ì ìˆ˜'].astype(float).describe())
    fig,ax=plt.subplots(figsize=(6,3))
    ax.hist(raw_df['ì ìˆ˜'].astype(float), bins=20)
    ax.set_title("íˆìŠ¤í† ê·¸ë¨")
    st.pyplot(fig)

# --- 4.3 ë¶„í¬/êµì°¨ë¶„ì„ ---
with tabs[2]:
    st.header("ë¶„í¬ ë° êµì°¨ë¶„ì„")
    # 1) ì ìˆ˜ ë¶„í¬ & Top10
    st.subheader("ì „ì²´ í‰ì  ë¶„í¬")
    fig1 = px.histogram(raw_df, x='ì ìˆ˜', nbins=20); st.plotly_chart(fig1)
    st.subheader("Top 10 í‰ì  ì‘í’ˆ")
    top10 = raw_df.nlargest(10,'ì ìˆ˜')[['ë“œë¼ë§ˆëª…','ì ìˆ˜']].sort_values('ì ìˆ˜')
    fig2 = px.bar(top10, x='ì ìˆ˜', y='ë“œë¼ë§ˆëª…', orientation='h', text='ì ìˆ˜'); st.plotly_chart(fig2)
    # 2) ì—°ë„ë³„ í”Œë«í¼ ìˆ˜(ì›ë³¸ explode)
    st.subheader("ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜")
    ct = (
        pd.DataFrame({'ë°©ì˜ë…„ë„': raw_df['ë°©ì˜ë…„ë„'], 'í”Œë«í¼': raw_df['í”Œë«í¼']})
        .explode('í”Œë«í¼')
        .groupby(['ë°©ì˜ë…„ë„', 'í”Œë«í¼']).size().reset_index(name='count'))
    ct['í”Œë«í¼_up'] = ct['í”Œë«í¼'].str.upper()
    focus = ['KBS', 'MBC', 'TVN', 'NETFLIX', 'SBS']

    fig3 = px.line(
        ct[ct['í”Œë«í¼_up'].isin(focus)],
        x='ë°©ì˜ë…„ë„',
        y='count',
        color='í”Œë«í¼',
        log_y=True,  # yì¶• ë¡œê·¸ ìŠ¤ì¼€ì¼ ì ìš©
        title="ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜ (ë¡œê·¸ ìŠ¤ì¼€ì¼)")
    st.plotly_chart(fig3)

    # 3) ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´
    st.subheader("ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´ í‰ê·  í‰ì  (ë°°ìš° ë‹¨ìœ„ ë°•ìŠ¤í”Œë¡¯)")

    # ë°°ìš°ë³„ ì¥ë¥´ ë‹¤ì–‘ì„± ê³„ì‚° â†’ ë©€í‹°/ë‹¨ì¼ ë¼ë²¨
    ag = (
        pd.DataFrame({'ë°°ìš°ëª…': raw_df['ë°°ìš°ëª…'], 'ì¥ë¥´': raw_df['ì¥ë¥´']})
        .explode('ì¥ë¥´')
        .groupby('ë°°ìš°ëª…')['ì¥ë¥´'].nunique()
    )
    multi_set = set(ag[ag > 1].index)

    label_map = {name: ('ë©€í‹°ì¥ë¥´' if name in multi_set else 'ë‹¨ì¼ì¥ë¥´') for name in ag.index}

    # ë°°ìš° ë‹¨ìœ„ í‰ê·  ì ìˆ˜
    actor_mean = (
        raw_df.groupby('ë°°ìš°ëª…', as_index=False)['ì ìˆ˜'].mean()
              .rename(columns={'ì ìˆ˜': 'ë°°ìš°í‰ê· ì ìˆ˜'})
    )
    actor_mean['ì¥ë¥´êµ¬ë¶„'] = actor_mean['ë°°ìš°ëª…'].map(label_map)

    # ë°•ìŠ¤í”Œë¡¯
    fig_box = px.box(
        actor_mean, 
        x='ì¥ë¥´êµ¬ë¶„', 
        y='ë°°ìš°í‰ê· ì ìˆ˜',
        title="ë©€í‹°ì¥ë¥´ vs ë‹¨ì¼ì¥ë¥´ ë°°ìš° ë‹¨ìœ„ í‰ê·  ì ìˆ˜ ë¶„í¬"
    )
    st.plotly_chart(fig_box, use_container_width=True)
    # 4) ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ
    st.subheader("ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ")

    # ì£¼ì—° ë°°ìš°ë§Œ í•„í„°ë§
    main_roles = raw_df[raw_df['ì—­í• '] == 'ì£¼ì—°'].copy()

    # ê²°í˜¼ìƒíƒœ ì»¬ëŸ¼ ìƒì„±: 'ë¯¸í˜¼' vs 'ë¯¸í˜¼ ì™¸'
    main_roles['ê²°í˜¼ìƒíƒœ'] = main_roles['ê²°í˜¼ì—¬ë¶€'].apply(lambda x: 'ë¯¸í˜¼' if x == 'ë¯¸í˜¼' else 'ë¯¸í˜¼ ì™¸')

    # ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ê³„ì‚°
    avg_scores_by_marriage = main_roles.groupby('ê²°í˜¼ìƒíƒœ')['ì ìˆ˜'].mean()

    # ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(6, 5))
    bars = ax.bar(avg_scores_by_marriage.index, avg_scores_by_marriage.values,
                  color=['mediumseagreen', 'gray'])

    # ìˆ˜ì¹˜ í‘œì‹œ
    for bar in bars:
        yval = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2, yval + 0.005,
                f'{yval:.3f}',
                ha='center', va='bottom', fontsize=12, fontweight='bold')

    ax.set_title('ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ', fontsize=14)
    ax.set_ylabel('í‰ê·  ì ìˆ˜')
    ax.set_xlabel('ê²°í˜¼ ìƒíƒœ')
    ax.set_ylim(min(avg_scores_by_marriage.values) - 0.05, max(avg_scores_by_marriage.values) + 0.05)
    ax.grid(axis='y', linestyle='--', alpha=0.5)

    st.pyplot(fig)
    st.subheader("ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜")

    # í•œê¸€ í°íŠ¸(Windows) + ë§ˆì´ë„ˆìŠ¤ ê¹¨ì§ ë°©ì§€
    import matplotlib, platform
    if platform.system() == "Windows":
        matplotlib.rcParams["font.family"] = "Malgun Gothic"
    matplotlib.rcParams["axes.unicode_minus"] = False

    import matplotlib.pyplot as plt
    import seaborn as sns
    import numpy as np
    import pandas as pd

    # ì¥ë¥´ê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° í¼ì¹˜ê¸° + ê²°ì¸¡ ì œê±°
    df_exploded = raw_df.explode('ì¥ë¥´')
    df_exploded = df_exploded.dropna(subset=['ì¥ë¥´', 'ì ìˆ˜'])

    # ì¥ë¥´ë³„ í‰ê·  ì ìˆ˜ ë° ì‘í’ˆ ìˆ˜
    genre_score = df_exploded.groupby('ì¥ë¥´')['ì ìˆ˜'].mean().round(3)
    genre_count = df_exploded['ì¥ë¥´'].value_counts()

    genre_df = (pd.DataFrame({'í‰ê·  ì ìˆ˜': genre_score, 'ì‘í’ˆ ìˆ˜': genre_count})
                .reset_index().rename(columns={'index': 'ì¥ë¥´'}))

    # ë³´ê¸° ì¢‹ê²Œ ì‘í’ˆ ìˆ˜ ê¸°ì¤€ ì •ë ¬
    genre_df = genre_df.sort_values('ì‘í’ˆ ìˆ˜', ascending=False).reset_index(drop=True)

    # ì‹œê°í™”
    fig, ax1 = plt.subplots(figsize=(12, 6))

    # ë§‰ëŒ€ê·¸ë˜í”„: ì‘í’ˆ ìˆ˜
    bars = ax1.bar(range(len(genre_df)), genre_df['ì‘í’ˆ ìˆ˜'], color='lightgray')
    ax1.set_ylabel('ì‘í’ˆ ìˆ˜', fontsize=12)
    ax1.set_xticks(range(len(genre_df)))
    ax1.set_xticklabels(genre_df['ì¥ë¥´'], rotation=45, ha='right')

    # ë§‰ëŒ€ ìœ„ ìˆ˜ì¹˜
    for i, rect in enumerate(bars):
        h = rect.get_height()
        ax1.text(i, h + max(2, h*0.01), f'{int(h)}',
                 ha='center', va='bottom', fontsize=10, fontweight='bold', color='#444')

    # ì„ ê·¸ë˜í”„: í‰ê·  ì ìˆ˜(ë³´ì¡°ì¶•)
    ax2 = ax1.twinx()
    sns.lineplot(x=range(len(genre_df)), y=genre_df['í‰ê·  ì ìˆ˜'],
                 marker='o', linewidth=2, ax=ax2)
    ax2.set_ylabel('í‰ê·  ì ìˆ˜', fontsize=12)
    ax2.tick_params(axis='y')
    ax2.set_ylim(genre_df['í‰ê·  ì ìˆ˜'].min() - 0.1, genre_df['í‰ê·  ì ìˆ˜'].max() + 0.1)

    # ì  ìœ„ ìˆ˜ì¹˜
    for i, v in enumerate(genre_df['í‰ê·  ì ìˆ˜']):
        ax2.text(i, v + 0.01, f'{v:.3f}',
                 ha='center', va='bottom', fontsize=10, fontweight='bold')

    plt.title('ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜', fontsize=14)
    ax1.set_xlabel('ì¥ë¥´', fontsize=12)
    ax1.grid(axis='y', linestyle='--', alpha=0.5)
    plt.tight_layout()

    st.pyplot(fig)

    st.subheader("ë°©ì˜ ìš”ì¼ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜ (ì›”â†’ì¼)")

    import matplotlib.pyplot as plt
    import pandas as pd

    # 1) ë°ì´í„° ì „ì²˜ë¦¬
    df_exploded = raw_df.explode('ë°©ì˜ìš”ì¼').dropna(subset=['ë°©ì˜ìš”ì¼', 'ì ìˆ˜']).copy()
    df_exploded['ë°©ì˜ìš”ì¼'] = df_exploded['ë°©ì˜ìš”ì¼'].astype(str).str.strip().str.lower()

    ordered_days_en = ['monday','tuesday','wednesday','thursday','friday','saturday','sunday']
    day_label_ko = {
        'monday':'ì›”', 'tuesday':'í™”', 'wednesday':'ìˆ˜', 'thursday':'ëª©',
        'friday':'ê¸ˆ', 'saturday':'í† ', 'sunday':'ì¼'
    }

    # 2) ì§‘ê³„ (ì—† ëŠ” ìš”ì¼ì€ 0/NaN ì²˜ë¦¬ í›„ ì •ë ¬)
    mean_score_by_day = (
        df_exploded.groupby('ë°©ì˜ìš”ì¼')['ì ìˆ˜'].mean()
        .reindex(ordered_days_en)
    )
    count_by_day = (
        df_exploded['ë°©ì˜ìš”ì¼'].value_counts()
        .reindex(ordered_days_en)
        .fillna(0).astype(int)
    )

    # 3) ì‹œê°í™”
    fig, ax1 = plt.subplots(figsize=(10, 6))

    # ì™¼ìª½ Yì¶•: ì‘í’ˆ ìˆ˜(ë§‰ëŒ€)
    bars = ax1.bar(ordered_days_en, count_by_day.values, alpha=0.3, color='tab:gray')
    ax1.set_ylabel('ì‘í’ˆ ìˆ˜', color='tab:gray', fontsize=12)
    ax1.tick_params(axis='y', labelcolor='tab:gray')

    # ë§‰ëŒ€ ìœ„ ìˆ˜ì¹˜
    for bar in bars:
        h = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2, h + 0.5, f'{int(h)}',
                 ha='center', va='bottom', fontsize=9, color='black')

    # ì˜¤ë¥¸ìª½ Yì¶•: í‰ê·  ì ìˆ˜(ì„ )
    ax2 = ax1.twinx()
    ax2.plot(ordered_days_en, mean_score_by_day.values, marker='o', color='tab:blue')
    ax2.set_ylabel('í‰ê·  ì ìˆ˜', color='tab:blue', fontsize=12)
    ax2.tick_params(axis='y', labelcolor='tab:blue')
    if mean_score_by_day.notna().any():
        ax2.set_ylim(mean_score_by_day.min() - 0.05, mean_score_by_day.max() + 0.05)

    # ì  ìœ„ ìˆ˜ì¹˜
    for x, y in zip(ordered_days_en, mean_score_by_day.values):
        if pd.notna(y):
            ax2.text(x, y + 0.005, f'{y:.3f}', color='tab:blue', fontsize=9, ha='center')

    # xì¶• í•œê¸€ ë ˆì´ë¸”
    ax1.set_xticks(ordered_days_en)
    ax1.set_xticklabels([day_label_ko[d] for d in ordered_days_en])

    plt.title('ë°©ì˜ ìš”ì¼ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜ (ì›”ìš”ì¼ â†’ ì¼ìš”ì¼ ìˆœ)', fontsize=14)
    plt.tight_layout()
    st.pyplot(fig)



# --- 4.4 ì›Œë“œí´ë¼ìš°ë“œ ---
with tabs[3]:
    st.header("ì›Œë“œí´ë¼ìš°ë“œ")
    if genre_list:
        wc = WordCloud(width=800,height=400,background_color='white').generate(' '.join(genre_list))
        fig,ax=plt.subplots(); ax.imshow(wc,interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)
    if broadcaster_list:
        wc = WordCloud(width=800,height=400,background_color='white').generate(' '.join(broadcaster_list))
        fig,ax=plt.subplots(); ax.imshow(wc,interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)
    if week_list:
        wc = WordCloud(width=800,height=400,background_color='white').generate(' '.join(week_list))
        fig,ax=plt.subplots(); ax.imshow(wc,interpolation='bilinear'); ax.axis('off'); st.pyplot(fig)

# --- 4.5 ì‹¤ì‹œê°„ í•„í„° ---
with tabs[4]:
    st.header("ì‹¤ì‹œê°„ í•„í„°")
    smin,smax = float(raw_df['ì ìˆ˜'].min()), float(raw_df['ì ìˆ˜'].max())
    sfilter = st.slider("ìµœì†Œ í‰ì ", smin,smax,smin)
    yfilter = st.slider("ë°©ì˜ë…„ë„ ë²”ìœ„", int(raw_df['ë°©ì˜ë…„ë„'].min()),int(raw_df['ë°©ì˜ë…„ë„'].max()),(2000,2025))
    filt = raw_df[(raw_df['ì ìˆ˜']>=sfilter)&raw_df['ë°©ì˜ë…„ë„'].between(*yfilter)]
    st.dataframe(filt.head(20))

# --- 4.6 ì „ì²´ ë¯¸ë¦¬ë³´ê¸° ---
with tabs[5]:
    st.header("ì›ë³¸ ì „ì²´ë³´ê¸°")
    st.dataframe(raw_df, use_container_width=True)

# --- 4.7 ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§ ---
with tabs[6]:
    st.header("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§")
    if feature_cols:
        X = df[feature_cols].copy()
        y = raw_df['ì ìˆ˜'].astype(float)
        X = preprocess_ml_features(X)
        X = pd.get_dummies(X, drop_first=True)
        X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=test_size,random_state=42)
        model = RandomForestRegressor(random_state=42) if model_type=="Random Forest" else LinearRegression()
        model.fit(X_train,y_train)
        y_pred = model.predict(X_test)
        st.metric("RÂ²", f"{r2_score(y_test,y_pred):.3f}")
        st.metric("MSE", f"{mean_squared_error(y_test,y_pred):.3f}")
    else:
        st.warning("ì‚¬ì´ë“œë°”ì—ì„œ íŠ¹ì„±ì„ ì„ íƒí•˜ì„¸ìš”.")

# --- 4.8 GridSearch íŠœë‹ ---
with tabs[7]:
    st.header("GridSearchCV íŠœë‹")
    st.info("ëª¨ë¸ì„ ì„ íƒí•˜ê³  GridSearchCVë¥¼ ì‹¤í–‰í•´ ë³´ì„¸ìš”.")

    # âš ï¸ ì „ì œ: X_train, X_test, y_train, y_test ê°€ ì´ë¯¸ ì¤€ë¹„ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
    # íšŒê·€ ë¬¸ì œ ê¸°ì¤€ scoring ì˜ˆì‹œ: neg_mean_squared_error (ì›í•˜ë©´ ë°”ê¿”ë„ ë¨)
    scoring = st.selectbox("ìŠ¤ì½”ì–´ë§", ["neg_mean_squared_error", "r2"], index=0)
    cv = st.number_input("CV í´ë“œ ìˆ˜", min_value=3, max_value=10, value=5, step=1)

    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import PolynomialFeatures, StandardScaler
    from sklearn.neighbors import KNeighborsRegressor
    from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor
    from sklearn.svm import SVR
    from sklearn.tree import DecisionTreeRegressor
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.model_selection import GridSearchCV
    import pandas as pd
    import numpy as np

    # 1) ëª¨ë¸ íŒ©í† ë¦¬ (ì „ë¶€ 'model' ì´ë¼ëŠ” ìŠ¤í… ì´ë¦„ìœ¼ë¡œ í†µì¼)
    model_zoo = {
        "KNN": KNeighborsRegressor(),
        "Linear Regression": LinearRegression(),
        "Ridge": Ridge(),
        "Lasso": Lasso(),
        "ElasticNet": ElasticNet(max_iter=10000),
        "SGDRegressor": SGDRegressor(max_iter=10000),
        "SVR": SVR(),
        "Decision Tree": DecisionTreeRegressor(random_state=42),
        "Random Forest": RandomForestRegressor(random_state=42),
    }

    # 2) ê³µí†µ íŒŒì´í”„ë¼ì¸: ë‹¤ìˆ˜ ëª¨ë¸ì—ì„  Poly+Scaleê°€ ìœ íš¨
    #    - íŠ¸ë¦¬/ëœë¤í¬ë ˆìŠ¤íŠ¸ëŠ” ë‹¤í•­/ìŠ¤ì¼€ì¼ ë¶ˆí•„ìš” â†’ ê·¸ ëª¨ë¸ì€ ë³„ë„ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
    def make_pipeline(name):
        if name in ["Decision Tree", "Random Forest"]:
            return Pipeline([("model", model_zoo[name])])  # ë‹¨ìˆœ
        else:
            return Pipeline([
                ("poly", PolynomialFeatures(include_bias=False)),
                ("scaler", StandardScaler()),
                ("model", model_zoo[name]),
            ])

    # 3) íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ (ëª¨ë‘ model__* ë¡œ ì •ê·œí™”)
    #    * ìš”ì²­ ì£¼ì‹  ë²”ìœ„ë¥¼ ê·¸ëŒ€ë¡œ ë°˜ì˜í•˜ë˜, ì˜¤íƒ€/ë„¤ì´ë°ì„ íŒŒì´í”„ë¼ì¸ì— ë§ê²Œ ìˆ˜ì •
    param_grids = {
        "KNN": {
            "poly__degree": [1, 2, 3],
            "model__n_neighbors": [3,4,5,6,7,8,9,10],
        },
        "Linear Regression": {
            "poly__degree": [1, 2, 3],
        },
        "Ridge": {
            "poly__degree": [1, 2, 3],
            "model__alpha": [0.001, 0.01, 0.1, 1, 10, 100, 1000],
        },
        "Lasso": {
            "poly__degree": [1, 2, 3],
            "model__alpha": [0.001, 0.01, 0.1, 1, 10, 100, 1000],
        },
        "ElasticNet": {
            "poly__degree": [1, 2, 3],
            "model__alpha": [0.001, 0.01, 0.1, 1, 10, 100, 1000],
            "model__l1_ratio": [0.1, 0.5, 0.9],
        },
        "SGDRegressor": {
            "poly__degree": [1, 2, 3],
            "model__learning_rate": ["constant", "invscaling", "adaptive"],
            # í•„ìš”ì‹œ eta0 ë“±ë„ ì¶”ê°€ ê°€ëŠ¥: "model__eta0": [0.001, 0.01, 0.1]
        },
        "SVR": {
            "poly__degree": [1, 2, 3],  # poly ì»¤ë„ì¼ ë•Œë§Œ ì˜ë¯¸ ìˆì§€ë§Œ, í•¨ê»˜ íŠœë‹í•´ë„ ë¬´ë°©
            "model__kernel": ["poly", "rbf", "sigmoid"],
            "model__degree": [1, 2, 3],
        },
        "Decision Tree": {
            # poly/scale ì—†ìŒ
            "model__max_depth": [10, 15, 20, 25, 30],
            "model__min_samples_split": [5, 6, 7, 8, 9, 10],
            "model__min_samples_leaf": [2, 3, 4, 5],
            "model__max_leaf_nodes": [None, 10, 20, 30],
        },
        "Random Forest": {
            # poly/scale ì—†ìŒ
            "model__n_estimators": [100, 200, 300],
            "model__min_samples_split": [5, 6, 7, 8, 9, 10],
            "model__max_depth": [5, 10, 15, 20, 25, 30],
        },
    }

    model_name = st.selectbox(
        "íŠœë‹í•  ëª¨ë¸ ì„ íƒ",
        list(model_zoo.keys()),
        index=0
    )

    run = st.button("GridSearch ì‹¤í–‰")

    if run:
        pipe = make_pipeline(model_name)
        grid = param_grids[model_name]

        gs = GridSearchCV(
            estimator=pipe,
            param_grid=grid,
            scoring=scoring,
            cv=cv,
            n_jobs=-1,
            refit=True,
            return_train_score=True,
        )
        with st.spinner("GridSearchCV ì‹¤í–‰ ì¤‘..."):
            gs.fit(X_train, y_train)

        st.success("ì™„ë£Œ!")

        # ê²°ê³¼ ìš”ì•½
        st.subheader("ë² ìŠ¤íŠ¸ ê²°ê³¼")
        st.write("Best Params:", gs.best_params_)
        st.write("Best CV Score:", gs.best_score_)

        # í…ŒìŠ¤íŠ¸ì…‹ í‰ê°€
        y_pred = gs.predict(X_test)
        from sklearn.metrics import mean_squared_error, r2_score
        test_mse = mean_squared_error(y_test, y_pred)
        test_r2 = r2_score(y_test, y_pred)
        st.write(f"Test MSE: {test_mse:.6f}")
        st.write(f"Test R2 : {test_r2:.6f}")

        # CV ìƒì„¸ ê²°ê³¼ í‘œ
        cvres = pd.DataFrame(gs.cv_results_)
        wanted_cols = [
            "rank_test_score",
            "mean_test_score",
            "std_test_score",
            "mean_train_score",
            "std_train_score",
            "params",
        ]
        st.dataframe(cvres[wanted_cols].sort_values("rank_test_score").reset_index(drop=True))


# --- 4.9 ì˜ˆì¸¡ ì‹¤í–‰ ---
with tabs[8]:
    st.header("í‰ì  ì˜ˆì¸¡")
    st.subheader("1) ëª¨ë¸ ì„¤ì •")
    model_type  = st.selectbox('ëª¨ë¸ ì„ íƒ', ['Random Forest', 'Linear Regression'])
    test_size   = st.slider('í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨', 0.1, 0.5, 0.2, 0.05)
    feature_cols = st.multiselect(
        'íŠ¹ì„± ì„ íƒ',
        ['ë‚˜ì´','ë°©ì˜ë…„ë„','ì„±ë³„','ì¥ë¥´','ë°°ìš°ëª…','í”Œë«í¼','ê²°í˜¼ì—¬ë¶€'],
        default=['ë‚˜ì´','ë°©ì˜ë…„ë„','ì¥ë¥´']
    )

    st.markdown("---")
    st.subheader("2) ì˜ˆì¸¡ ì…ë ¥")
    input_age     = st.number_input("ë°°ìš° ë‚˜ì´", 10, 80, 30)
    input_year    = st.number_input("ë°©ì˜ë…„ë„", 2000, 2025, 2021)
    input_gender  = st.selectbox("ì„±ë³„", sorted(df['ì„±ë³„'].dropna().unique()))

    genre_opts    = sorted(unique_genres)
    default_genre = [genre_opts[0]] if genre_opts else []
    input_genre   = st.multiselect("ì¥ë¥´", genre_opts, default=default_genre)

    platform_opts = sorted(set(broadcaster_list))
    default_plat  = [platform_opts[0]] if platform_opts else []
    input_plat    = st.multiselect("í”Œë«í¼", platform_opts, default=default_plat)

    input_married = st.selectbox("ê²°í˜¼ì—¬ë¶€", sorted(df['ê²°í˜¼ì—¬ë¶€'].dropna().unique()))

    predict_btn   = st.button("ì˜ˆì¸¡ ì‹¤í–‰")

    if predict_btn:
        # --- 1. í›ˆë ¨ ë°ì´í„° ì „ì²˜ë¦¬ ---
        X_all = raw_df[feature_cols].copy()
        y_all = df['ì ìˆ˜'].astype(float)
        X_all = preprocess_ml_features(X_all)
        X_all = pd.get_dummies(X_all, columns=[c for c in X_all.columns if X_all[c].dtype=='object'])

        # --- 2. ì…ë ¥ ë°ì´í„° ì „ì²˜ë¦¬ ---
        user_df = pd.DataFrame([{
            'ë‚˜ì´': input_age,
            'ë°©ì˜ë…„ë„': input_year,
            'ì„±ë³„': input_gender,
            'ì¥ë¥´': input_genre,
            'ë°°ìš°ëª…': df['ë°°ìš°ëª…'].dropna().iloc[0],  # í•„ìš”ì‹œ selectboxë¡œ ë³€ê²½
            'í”Œë«í¼': input_plat,
            'ê²°í˜¼ì—¬ë¶€': input_married
        }])
        u = preprocess_ml_features(user_df)
        u = pd.get_dummies(u, columns=[c for c in u.columns if u[c].dtype=='object'])
        for c in X_all.columns:
            if c not in u.columns:
                u[c] = 0
        u = u[X_all.columns]

        # --- 3. ëª¨ë¸ í•™ìŠµ & ì˜ˆì¸¡ ---
        model = RandomForestRegressor(n_estimators=100, random_state=42) \
                if model_type=="Random Forest" else LinearRegression()
        model.fit(X_all, y_all)
        pred = model.predict(u)[0]

        st.success(f"ğŸ’¡ ì˜ˆìƒ í‰ì : {pred:.2f}")


# =========================
# 6. ì˜ˆì¸¡ ì‹¤í–‰
# =========================
        if predict_btn:
            user_input = pd.DataFrame([{
                'ë‚˜ì´': input_age,
                'ë°©ì˜ë…„ë„': input_year,
                'ì„±ë³„': input_gender,
                'ì¥ë¥´': input_genre,
                'ë°°ìš°ëª…': st.selectbox("ë°°ìš°ëª…", sorted(df['ë°°ìš°ëª…'].dropna().unique())),  # ëª¨ë¸ë§ íƒ­ê³¼ ë™ì¼í•˜ê²Œ
                'í”Œë«í¼': input_plat,
                'ê²°í˜¼ì—¬ë¶€': input_married
            }])
        
            # ì „ì²˜ë¦¬ & ì¸ì½”ë”©
            X_all = df[feature_cols].copy()
            y_all = df['ì ìˆ˜'].astype(float)
            X_all = preprocess_ml_features(X_all)
            X_all = pd.get_dummies(X_all, columns=[c for c in X_all.columns if X_all[c].dtype == 'object'])
        
            user_proc = preprocess_ml_features(user_input)
            user_proc = pd.get_dummies(user_proc, columns=[c for c in user_proc.columns if user_proc[c].dtype == 'object'])
            for col in X_all.columns:
                if col not in user_proc.columns:
                    user_proc[col] = 0
            user_proc = user_proc[X_all.columns]
        
            # ëª¨ë¸ í•™ìŠµ & ì˜ˆì¸¡
            model = RandomForestRegressor(n_estimators=100, random_state=42) if model_type=="Random Forest" else LinearRegression()
            model.fit(X_all, y_all)
            prediction = model.predict(user_proc)[0]
        
            st.success(f"ğŸ’¡ ì˜ˆìƒ í‰ì : {prediction:.2f}")
