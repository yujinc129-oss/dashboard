# app.py
# ---- dependency guard (optional) ----
import importlib.util, streamlit as st
_missing = [m for m in ("numpy","scipy","sklearn","joblib","threadpoolctl","xgboost") if importlib.util.find_spec(m) is None]
if _missing:
    st.error(f"í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜: {_missing}. requirements.txt / runtime.txt ë²„ì „ì„ ê³ ì •í•´ ì¬ë°°í¬í•˜ì„¸ìš”.")
    st.stop()

# ===== í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ì²« ìŠ¤íŠ¸ë¦¼ë¦¿ í˜¸ì¶œ) =====
st.set_page_config(page_title="ì¼€ë¯¸ìŠ¤ì½”ì–´ | K-ë“œë¼ë§ˆ ë¶„ì„/ì˜ˆì¸¡", page_icon="ğŸ¬", layout="wide")

import os
import ast
import random
import numpy as np
import pandas as pd
from pathlib import Path
import platform
from sklearn.metrics import mean_squared_error
import plotly.express as px
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.base import clone
import re
from sklearn.model_selection import KFold
from sklearn.impute import SimpleImputer

# XGBê°€ ì„¤ì¹˜ë¼ ìˆìœ¼ë©´ ì“°ë„ë¡ ì•ˆì „í•˜ê²Œ ì¶”ê°€
try:
    from xgboost import XGBRegressor
    XGB_AVAILABLE = True
except Exception:
    XGB_AVAILABLE = False

def rmse(y_true, y_pred):
    return float(np.sqrt(mean_squared_error(y_true, y_pred)))

# --- column helper (paste after `raw_df = load_data()` ) ---
def _exists(col: str, df: pd.DataFrame = None) -> bool:
    df = raw_df if df is None else df
    try:
        return col in df.columns
    except Exception:
        return False

# --- helpers (add below _exists) ---
def _uniq(obj) -> int:
    """Series/iterableì—ì„œ NaN ì œì™¸ ê³ ìœ ê°’ ê°œìˆ˜."""
    try:
        s = obj if isinstance(obj, pd.Series) else pd.Series(obj)
        return int(s.dropna().astype(str).nunique())
    except Exception:
        return 0

# ===== Dashboard CSS (once) =====
def ensure_dashboard_css():
    if st.session_state.get("_chem_css_injected"):
        return
    st.session_state["_chem_css_injected"] = True
    st.markdown("""
    <style>
      .chem-kpi-card{
        background:#fff;border:1px solid #EEF2F7;border-radius:16px;
        box-shadow:0 4px 16px rgba(17,24,39,.04);padding:14px 16px 10px 16px;
      }
      .chem-kpi-title{font-size:12px;color:#6b7280;font-weight:700;margin-bottom:6px}
      .chem-kpi-main{display:flex;align-items:baseline;gap:8px}
      .chem-kpi-val{font-size:28px;font-weight:800;line-height:1}
      .chem-kpi-sub{font-size:12px;color:#10b981;font-weight:700}

      .chem-card{
        background:#fff;border:1px solid #EEF2F7;border-radius:16px;
        box-shadow:0 4px 16px rgba(17,24,39,.04);padding:16px 16px 12px 16px;
      }
      .chem-card h4{margin:0 0 6px 0;font-size:14px;color:#6b7280;font-weight:700}

      .chem-row{display:grid;grid-template-columns:repeat(12,1fr);gap:14px}
      .col-3{grid-column:span 3}.col-4{grid-column:span 4}
      .col-6{grid-column:span 6}.col-12{grid-column:span 12}
    </style>
    """, unsafe_allow_html=True)

# ===== ì „ì—­ ì‹œë“œ ê³ ì • =====
SEED = 42
os.environ["PYTHONHASHSEED"] = str(SEED)
random.seed(SEED); np.random.seed(SEED)

# ===== í•œê¸€ í°íŠ¸ ë¶€íŠ¸ìŠ¤íŠ¸ë© =====
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

if st.session_state.get("font_cache_cleared") is not True:
    import shutil
    shutil.rmtree(matplotlib.get_cachedir(), ignore_errors=True)
    st.session_state["font_cache_cleared"] = True

def ensure_korean_font():
    matplotlib.rcParams['axes.unicode_minus'] = False
    base = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()
    candidates = [
        base / "fonts" / "NanumGothic-Regular.ttf",
        base / "fonts" / "NanumGothic.ttf",
    ]
    if platform.system() == "Windows":
        candidates += [Path(r"C:\Windows\Fonts\malgun.ttf"), Path(r"C:\Windows\Fonts\malgunbd.ttf")]
    wanted = ("nanum","malgun","applegothic","notosanscjk","sourcehan","gulim","dotum",
              "batang","pretendard","gowun","spoqa")
    for f in fm.findSystemFonts(fontext="ttf"):
        if any(k in os.path.basename(f).lower() for k in wanted):
            candidates.append(Path(f))
    for p in candidates:
        try:
            if p.exists():
                fm.fontManager.addfont(str(p))
                family = fm.FontProperties(fname=str(p)).get_name()
                matplotlib.rcParams['font.family'] = family
                st.session_state["kfont_path"] = str(p)  # WordCloudìš©
                return family
        except Exception:
            continue
    st.session_state["kfont_path"] = None
    return None

_ = ensure_korean_font()

# ====== Global UI (Topbar + Cards) ======
def _inject_global_css():
    # ì¤‘ë³µ ì£¼ì… ë°©ì§€
    if st.session_state.get("_chem_css_injected"):
        return
    st.session_state["_chem_css_injected"] = True
    
    st.markdown("""
    <style>
      /* ë ˆì´ì•„ì›ƒ ì—¬ë°± ë‹¤ë“¬ê¸° */
      .block-container{padding-top:1.4rem; padding-bottom:2.2rem;}
      /* ì œëª© ì˜ì—­ */
      .chem-hero{display:flex; align-items:center; gap:12px; margin-bottom:10px;}
      .chem-hero h1{font-size:34px; line-height:1.1; font-weight:900; margin:0;}
      .chem-hero .logo{font-size:28px}

      /* ì¹´ë“œ ê·¸ë¦¬ë“œ */
      .chem-grid{display:grid; grid-template-columns:repeat(12,1fr); gap:14px;}
      .col-3{grid-column:span 3} .col-4{grid-column:span 4} .col-5{grid-column:span 5}
      .col-6{grid-column:span 6} .col-8{grid-column:span 8} .col-12{grid-column:span 12}

      /* ê³µí†µ ì¹´ë“œ */
      .chem-card{
        background:#fff; border:1px solid #eef2f7; border-radius:16px;
        box-shadow:0 6px 18px rgba(17,24,39,.05); padding:16px 16px 14px 16px;
      }
      .chem-card h4{margin:0 0 8px 0; font-size:13px; letter-spacing:.02em; color:#6b7280; font-weight:800}
      .chem-body{padding:4px 2px 0 2px}

      /* KPI ì¹´ë“œ */
      .kpi .value{font-size:28px; font-weight:900; letter-spacing:-.02em}
      .kpi .caption{font-size:12px; color:#9ca3af; margin-top:2px}

      /* Plotly ì¹´ë“œ ìƒë‹¨ ì—¬ë°± ì¤„ì´ê¸° */
      div[data-testid="stPlotlyChart"]{margin-top:4px}
      /* plotly í°íŠ¸ ìŠ¬ë¦¼ */
      .js-plotly-plot, .plotly .main-svg{font-family: Pretendard, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Noto Sans KR", "Apple SD Gothic Neo", "Malgun Gothic", Arial, sans-serif !important;}
    </style>
    """, unsafe_allow_html=True)
def _exists(col: str) -> bool:
    return col in raw_df.columns

def _first_col(*cands):
    for c in cands:
        if _exists(c): return c
    return None

def _uniq(obj) -> int:
    try:
        s = obj if isinstance(obj, pd.Series) else pd.Series(obj)
        return int(s.dropna().astype(str).nunique())
    except Exception:
        return 0

def _fmt(n):
    try:
        return f"{int(n):,}"
    except Exception:
        try: return f"{float(n):.2f}"
        except: return str(n)


def topbar(title: str, crumb: str = "HOME â–¸ DASHBOARD"):
    _inject_global_css()
    st.markdown(f"""
      <div class="chem-topbar">
        <div class="chem-toprow">
          <div>
            <div class="chem-brand">ğŸ¬ <span>{title}</span></div>
            <div class="chem-breadcrumb">{crumb}</div>
          </div>
          <div class="chem-right">
            <div class="chem-iconbtn" title="ì•Œë¦¼">ğŸ””</div>
            <div class="chem-chip">ğŸ‘¤ 2ì¡°</div>
          </div>
        </div>
      </div>
    """, unsafe_allow_html=True)

from contextlib import contextmanager

@contextmanager
def card(title: str = ""):
    _inject_global_css()
    st.markdown('<div class="chem-card">', unsafe_allow_html=True)
    if title:
        st.markdown(f"<h4>{title}</h4>", unsafe_allow_html=True)
    yield
    st.markdown('</div>', unsafe_allow_html=True)

def kpi_card(label: str, value: str, delta: str="", good=True):
    _inject_global_css()
    color = "#10b981" if good else "#ef4444"
    st.markdown(f"""
      <div class="chem-card">
        <h4>{label}</h4>
        <div class="chem-kpi">
          <div class="v">{value}</div>
          <div class="d" style="color:{color}">{delta}</div>
        </div>
      </div>
    """, unsafe_allow_html=True)


# ===== ì „ì²˜ë¦¬ ìœ í‹¸ =====
from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import r2_score
from sklearn.ensemble import RandomForestRegressor

def clean_cell_colab(x):
    if isinstance(x, list):
        return [str(i).strip() for i in x if pd.notna(i)]
    if pd.isna(x):
        return []
    if isinstance(x, str):
        try:
            parsed = ast.literal_eval(x)
            if isinstance(parsed, list):
                return [str(i).strip() for i in parsed if pd.notna(i)]
            return [x.strip()]
        except Exception:
            return [x.strip()]
    return [str(x).strip()]

def colab_multilabel_fit_transform(df: pd.DataFrame, cols=('genres','day','network')) -> pd.DataFrame:
    out = df.copy()
    for col in cols:
        out[col] = out[col].apply(clean_cell_colab)
        mlb = MultiLabelBinarizer()
        arr = mlb.fit_transform(out[col])
        new_cols = [f"{col}_{c.strip().upper()}" for c in mlb.classes_]
        out = out.drop(columns=[c for c in new_cols if c in out.columns], errors='ignore')
        out = pd.concat([out, pd.DataFrame(arr, columns=new_cols, index=out.index)], axis=1)
        st.session_state[f"mlb_{col}"] = mlb
        st.session_state[f"mlb_classes_{col}"] = mlb.classes_.tolist()
    return out

def colab_multilabel_transform(df: pd.DataFrame, cols=('genres','day','network')) -> pd.DataFrame:
    out = df.copy()
    for col in cols:
        out[col] = out[col].apply(clean_cell_colab)
        mlb = st.session_state.get(f"mlb_{col}", None)
        if mlb is None:
            classes = st.session_state.get(f"mlb_classes_{col}", [])
            mlb = MultiLabelBinarizer()
            if classes:
                mlb.classes_ = np.array(classes)
            else:
                try:
                    prefix = f"{col}_"
                    labels = [c[len(prefix):] for c in df_mlb.columns if c.startswith(prefix)]
                    if labels:
                        mlb.classes_ = np.array(labels)
                    else:
                        mlb.fit(out[col])
                except Exception:
                    mlb.fit(out[col])
        arr = mlb.transform(out[col])
        new_cols = [f"{col}_{c.strip().upper()}" for c in mlb.classes_]
        out = out.drop(columns=[c for c in new_cols if c in out.columns], errors='ignore')
        out = pd.concat([out, pd.DataFrame(arr, columns=new_cols, index=out.index)], axis=1)
    return out

def expand_feature_cols_for_training(base: pd.DataFrame, selected: list):
    cols = []
    for c in selected:
        if c in ('genres','day','network'):
            prefix = f"{c}_"
            cols += [k for k in base.columns if k.startswith(prefix)]
        else:
            cols.append(c)
    return cols

def build_X_from_selected(base: pd.DataFrame, selected: list) -> pd.DataFrame:
    X = pd.DataFrame(index=base.index)
    use_cols = expand_feature_cols_for_training(base, selected)
    if use_cols:
        X = pd.concat([X, base[use_cols]], axis=1)
    singles = [c for c in selected if c not in ('genres','day','network')]
    for c in singles:
        if c in base.columns and base[c].dtype == 'object':
            X = pd.concat([X, pd.get_dummies(base[c], prefix=c)], axis=1)
        elif c in base.columns:
            X[c] = base[c]
    return X

# ===== ë°ì´í„° ë¡œë“œ =====
@st.cache_data
def load_data():
    raw = pd.read_json('drama_d.json')
    if isinstance(raw, pd.Series):
        raw = pd.DataFrame({c: pd.Series(v) for c, v in raw.to_dict().items()})
    else:
        raw = pd.DataFrame({c: pd.Series(v) for c, v in raw.to_dict().items()})
    return raw

raw_df = load_data()

# ===== ë©€í‹°ë¼ë²¨ ì¸ì½”ë”© ê²°ê³¼ ìƒì„± (genres / day / network) =====
df_mlb = colab_multilabel_fit_transform(raw_df, cols=('genres','day','network'))

# ===== Colab ìŠ¤íƒ€ì¼ X/y, ì „ì²˜ë¦¬ ì •ì˜ =====
drop_cols = [c for c in ['ë°°ìš°ëª…','ë“œë¼ë§ˆëª…','genres','day','network','score','start airing'] if c in df_mlb.columns]

if 'score' in df_mlb.columns:
    df_mlb['score'] = pd.to_numeric(df_mlb['score'], errors='coerce')

X_colab_base = df_mlb.drop(columns=drop_cols, errors='ignore')
y_all = df_mlb['score']

categorical_features = [c for c in ['role','gender','air_q','married','age_group'] if c in X_colab_base.columns]

try:
    ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)
except TypeError:
    ohe = OneHotEncoder(drop='first', handle_unknown='ignore', sparse=False)

preprocessor = ColumnTransformer(
    transformers=[
        (
            'cat',
            Pipeline(steps=[
                ('imputer', SimpleImputer(strategy='constant', fill_value='(missing)')),
                ('ohe', ohe),
            ]),
            categorical_features
        )
    ],
    remainder='passthrough'
)

# ===== ê³µí†µ ë¦¬ìŠ¤íŠ¸ =====
def _flat_unique(series, cleaner=clean_cell_colab):
    return sorted({v for sub in series.dropna().apply(cleaner) for v in sub})

genre_list = _flat_unique(raw_df.get('genres', pd.Series(dtype=object)))
broadcaster_list = _flat_unique(raw_df.get('network', pd.Series(dtype=object)))
week_list = _flat_unique(raw_df.get('day', pd.Series(dtype=object)))
unique_genres = sorted(set(genre_list))

def age_to_age_group(age: int) -> str:
    s = raw_df.get('age_group')
    if s is None or s.dropna().empty:
        if age < 20: return "10ëŒ€"
        if age < 30: return "20ëŒ€"
        if age < 40: return "30ëŒ€"
        if age < 50: return "40ëŒ€"
        if age < 60: return "50ëŒ€"
        return "60ëŒ€ ì´ìƒ"

    series = s.dropna().astype(str)
    vocab = series.unique().tolist()
    counts = series.value_counts()
    decade = (int(age)//10)*10

    exact = [g for g in vocab if re.search(rf"{decade}\s*ëŒ€", g)]
    if exact: return counts[exact].idxmax()

    loose = [g for g in vocab if str(decade) in g]
    if loose: return counts[loose].idxmax()

    if decade >= 60:
        over = [g for g in vocab if ('60' in g) or ('ì´ìƒ' in g)]
        if over: return counts[over].idxmax()

    with_num = []
    for g in vocab:
        m = re.search(r'(\d+)', g)
        if m: with_num.append((g, int(m.group(1))))
    if with_num:
        nearest_num = min(with_num, key=lambda t: abs(t[1]-decade))[1]
        candidates = [g for g,n in with_num if n==nearest_num]
        return counts[candidates].idxmax()

    return counts.idxmax()

# ===== ê³µí†µ íŒŒì´í”„ë¼ì¸ ë¹Œë” =====
def make_pipeline(model_name, kind, estimator):
    if kind == "tree":
        return Pipeline([('preprocessor', preprocessor), ('model', estimator)])
    if model_name == "SVR":
        return Pipeline([('preprocessor', preprocessor), ('scaler', StandardScaler()), ('model', estimator)])
    if model_name == "KNN":
        return Pipeline([('preprocessor', preprocessor), ('poly', PolynomialFeatures(include_bias=False)),
                         ('scaler', StandardScaler()), ('knn', estimator)])
    if model_name == "Linear Regression (Poly)":
        return Pipeline([('preprocessor', preprocessor), ('poly', PolynomialFeatures(include_bias=False)),
                         ('scaler', StandardScaler()), ('linreg', estimator)])
    return Pipeline([('preprocessor', preprocessor), ('poly', PolynomialFeatures(include_bias=False)),
                     ('scaler', StandardScaler()), ('model', estimator)])

# ==============================
# ì‚¬ì´ë“œë°” ë„¤ë¹„ê²Œì´ì…˜
# ==============================
st.title("ğŸ’« ì¼€ë¯¸ìŠ¤ì½”ì–´")
NAV_ITEMS = [
    ("overview", "ğŸ ", "ê°œìš”"),
    ("basic",    "ğŸ“‹", "ê¸°ì´ˆí†µê³„"),
    ("dist",     "ğŸ“ˆ", "ë¶„í¬Â·êµì°¨"),
    ("filter",   "ğŸ› ï¸", "í•„í„°"),
    ("all",      "ğŸ—‚ï¸", "ì „ì²´ë³´ê¸°"),
    ("tuning",   "ğŸ§ª", "íŠœë‹"),
    ("ml",       "ğŸ¤–", "MLëª¨ë¸"),
    ("predict",  "ğŸ¯", "ì˜ˆì¸¡"),
]

# ----------------------------
# ì¿¼ë¦¬íŒŒëŒ ì•ˆì „ ì½ê¸° ìœ í‹¸ (ë²„ì „ í˜¸í™˜)
# ----------------------------
def _get_nav_from_query():
    if hasattr(st, "query_params"):  # Streamlit 1.30+
        qp = st.query_params
        val = qp.get("nav", None)
        if isinstance(val, list):
            val = val[0] if val else None
        return val
    else:
        qp = st.experimental_get_query_params()
        val = qp.get("nav", [None])
        return val[0] if isinstance(val, list) else val

def _set_nav_query(slug: str):
    if hasattr(st, "query_params"):   # Streamlit 1.30+
        st.query_params["nav"] = slug
    else:
        st.experimental_set_query_params(nav=slug)

# ----------------------------
# í˜„ì¬ nav ê²°ì • (ì´ˆê¸° 1íšŒ)
# ----------------------------
if "nav" not in st.session_state:
    st.session_state["nav"] = _get_nav_from_query() or NAV_ITEMS[0][0]
current = st.session_state["nav"]

# ================== ì‚¬ì´ë“œë°” UI ==================
with st.sidebar:
    st.markdown("""
    <style>
      section[data-testid="stSidebar"]{
        width:80px !important; min-width:80px; background:#202331;
      }
      .chem-stack{display:flex; flex-direction:column; align-items:center; gap:14px; padding:12px 0 24px;}
      .chem-btn .stButton>button{
        width:46px; height:46px; font-size:26px; line-height:1;
        border-radius:14px; border:1px solid rgba(255,255,255,.15);
        background:transparent; color:#ffb7a5; transition:all .15s ease;
      }
      .chem-btn .stButton>button:hover{
        transform:translateY(-2px);
        border-color:#ff7a59; box-shadow:0 4px 12px rgba(0,0,0,.25);
      }
      .chem-btn.active .stButton>button{
        background:#ff7a59; color:#fff; border-color:#ff7a59;
      }
    </style>
    """, unsafe_allow_html=True)

    st.markdown('<div class="chem-stack">', unsafe_allow_html=True)

    # ì•„ì´ì½˜ ë²„íŠ¼ ë Œë”ë§
    for slug, icon, label in NAV_ITEMS:
        is_active = (slug == current)
        st.markdown(f'<div class="chem-btn {"active" if is_active else ""}">', unsafe_allow_html=True)
        clicked = st.button(icon, key=f"nav_{slug}", help=label)
        st.markdown('</div>', unsafe_allow_html=True)

        if clicked and not is_active:
            st.session_state["nav"] = slug
            _set_nav_query(slug)  # URL ë™ê¸°í™”(ìƒˆ íƒ­ ì•„ë‹˜)
            st.rerun()

    st.markdown('</div>', unsafe_allow_html=True)

# ì´í›„ì—” current ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë¼ìš°íŒ…:
# if current == "overview": page_overview()
# elif current == "basic":  page_basic_stats()
# ...


# ==============================
# í˜ì´ì§€ í•¨ìˆ˜ë“¤
# ==============================
def page_overview():
    ensure_dashboard_css() 

    # ---------- íƒ€ì´í‹€(íˆì–´ë¡œ) ----------
    st.markdown(
        """
        <div class="chem-hero">
          <div class="logo">ğŸ’«</div>
          <h1>ì¼€ë¯¸ìŠ¤ì½”ì–´</h1>
        </div>
        """,
        unsafe_allow_html=True
    )

    # ---------- ì§€í‘œ ê³„ì‚° ----------
    drama_col = _first_col("ë“œë¼ë§ˆëª…", "title", "Title", "name")
    actor_col = _first_col("ë°°ìš°ëª…", "actor", "Actor")
    score_s   = pd.to_numeric(raw_df.get("score"), errors="coerce")

    total_titles = _uniq(raw_df[drama_col]) if drama_col else raw_df.shape[0]
    total_actors = _uniq(raw_df[actor_col]) if actor_col else 0
    avg_score    = float(score_s.mean()) if score_s.notna().any() else float("nan")

    top_title_txt = "-"
    top_title_val = float("nan")
    if drama_col and score_s.notna().any():
        tops = (raw_df[[drama_col, "score"]].copy())
        tops["score"] = pd.to_numeric(tops["score"], errors="coerce")
        tops = tops.dropna()
        if not tops.empty:
            g = tops.groupby(drama_col)["score"].mean().sort_values(ascending=False)
            top_title_val = float(g.iloc[0])
            top_title_txt = f"{g.index[0]} ({top_title_val:.2f})"

    # ---------- KPI 4ì¥ ----------
    kpi_cols = st.columns(4)
    with kpi_cols[0]:
        st.markdown(
            f"""
            <div class="chem-card kpi">
              <h4>TOTAL TITLES</h4>
              <div class="value">{_fmt(total_titles)}</div>
              <div class="caption">ì „ì²´ ì‘í’ˆ</div>
            </div>
            """, unsafe_allow_html=True
        )
    with kpi_cols[1]:
        st.markdown(
            f"""
            <div class="chem-card kpi">
              <h4>TOTAL ACTORS</h4>
              <div class="value">{_fmt(total_actors)}</div>
              <div class="caption">ëª…</div>
            </div>
            """, unsafe_allow_html=True
        )
    with kpi_cols[2]:
        st.markdown(
            f"""
            <div class="chem-card kpi">
              <h4>AVG CHEMI SCORE</h4>
              <div class="value">{avg_score:.2f if not np.isnan(avg_score) else 0}</div>
              <div class="caption">ì „ì²´ í‰ê· </div>
            </div>
            """, unsafe_allow_html=True
        )
    with kpi_cols[3]:
        st.markdown(
            f"""
            <div class="chem-card kpi">
              <h4>TOP TITLE (AVG)</h4>
              <div class="value">{top_title_val:.2f if not np.isnan(top_title_val) else 0}</div>
              <div class="caption">{top_title_txt}</div>
            </div>
            """, unsafe_allow_html=True
        )

    st.write("")  # ì‚´ì§ ê³µë°±

    # ---------- ì°¨íŠ¸ 2ì¥ (ì—°ë„ í‰ê·  / ì¥ë¥´ í‰ê· ) ----------
    left, right = st.columns([7,5])

    # ì—°ë„ë³„ í‰ê· 
    with left:
        st.markdown('<div class="chem-card"><h4>PERCENTAGE (ì—°ë„ë³„ í‰ê·  ì¼€ë¯¸ìŠ¤ì½”ì–´)</h4><div class="chem-body">', unsafe_allow_html=True)
        if _exists("start airing"):
            ydf = raw_df.copy()
            ydf["start airing"] = pd.to_numeric(ydf["start airing"], errors="coerce")
            ydf["score"] = pd.to_numeric(ydf["score"], errors="coerce")
            ydf = ydf.dropna(subset=["start airing","score"])
            if not ydf.empty:
                y = (ydf.groupby("start airing")["score"].mean().reset_index()
                       .sort_values("start airing"))
                fig = px.line(y, x="start airing", y="score",
                              markers=True, template="simple_white",
                              height=360)
                fig.update_traces(line_width=3)
                fig.update_layout(margin=dict(l=10,r=10,t=8,b=0), yaxis_title=None, xaxis_title=None)
                st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})
            else:
                st.info("ì—°ë„/ì ìˆ˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            st.info("`start airing` ì»¬ëŸ¼ì´ ì—†ì–´ ì—°ë„ë³„ ì°¨íŠ¸ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
        st.markdown('</div></div>', unsafe_allow_html=True)

    # ì¥ë¥´ë³„ í‰ê· (Top 8)
    with right:
        st.markdown('<div class="chem-card"><h4>TOTAL ORDERS (ì¥ë¥´ë³„ í‰ê·  ì¼€ë¯¸ìŠ¤ì½”ì–´)</h4><div class="chem-body">', unsafe_allow_html=True)
        if _exists("genres"):
            gdf = raw_df.copy()
            gdf["score"] = pd.to_numeric(gdf["score"], errors="coerce")
            gdf["genres"] = gdf["genres"].apply(clean_cell_colab)
            gdf = gdf.explode("genres").dropna(subset=["genres","score"])
            if not gdf.empty:
                topg = (gdf.groupby("genres")["score"].mean().sort_values(ascending=False)
                          .head(8).reset_index())
                fig2 = px.bar(topg, x="genres", y="score", template="simple_white", height=360)
                fig2.update_layout(margin=dict(l=10,r=10,t=8,b=0), yaxis_title=None, xaxis_title=None)
                st.plotly_chart(fig2, use_container_width=True, config={"displayModeBar": False})
            else:
                st.info("ì¥ë¥´/ì ìˆ˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        else:
            st.info("`genres` ì»¬ëŸ¼ì´ ì—†ì–´ ì¥ë¥´ ì°¨íŠ¸ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
        st.markdown('</div></div>', unsafe_allow_html=True)

    # ---------- í•˜ë‹¨ 2ì¥ : ìµœê·¼ ìƒìœ„ì‘ / ë°ì´í„° ì•Œë¦¼ ----------
    st.write("")
    col_a, col_b = st.columns(2)

    with col_a:
        st.markdown('<div class="chem-card"><h4>ìµœê·¼ ìƒìœ„ ì‘í’ˆ TOP 5</h4><div class="chem-body">', unsafe_allow_html=True)
        if drama_col:
            tmp = raw_df[[drama_col, "score"]].copy()
            tmp["score"] = pd.to_numeric(tmp["score"], errors="coerce")
            tmp = tmp.dropna()
            if not tmp.empty:
                tb = (tmp.groupby(drama_col)["score"].mean()
                        .sort_values(ascending=False).head(5).round(2))
                st.table(tb.reset_index().rename(columns={drama_col:"ì‘í’ˆ", "score":"í‰ê· "}))
            else:
                st.caption("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.caption("ë“œë¼ë§ˆëª… ì»¬ëŸ¼ì´ ì—†ì–´ ëª©ë¡ì„ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown('</div></div>', unsafe_allow_html=True)

    with col_b:
        st.markdown('<div class="chem-card"><h4>ë°ì´í„° ìƒíƒœ</h4><div class="chem-body">', unsafe_allow_html=True)
        null_ratio = (raw_df.isnull().mean()*100).sort_values(ascending=False).round(1).head(6)
        st.caption("ê²°ì¸¡ì¹˜ ë¹„ìœ¨ ìƒìœ„ ì»¬ëŸ¼(%)")
        st.table(null_ratio.reset_index().rename(columns={"index":"ì»¬ëŸ¼","": "ê²°ì¸¡(%)", 0:"ê²°ì¸¡(%)"}))
        st.markdown('</div></div>', unsafe_allow_html=True)
def page_basic_stats():
    st.header("ê¸°ì´ˆ í†µê³„: score")
    st.write(pd.to_numeric(raw_df['score'], errors='coerce').describe())
    fig,ax=plt.subplots(figsize=(6,3))
    ax.hist(pd.to_numeric(raw_df['score'], errors='coerce'), bins=20)
    ax.set_title("ì „ì²´ í‰ì  ë¶„í¬")
    st.pyplot(fig)

def page_dist_cross():
    st.header("ë¶„í¬ ë° êµì°¨ë¶„ì„")

    # ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜
    st.subheader("ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜")
    ct = (
        pd.DataFrame({'start airing': raw_df['start airing'],
                      'network': raw_df['network'].apply(clean_cell_colab)})
        .explode('network').groupby(['start airing','network']).size().reset_index(name='count')
    )
    ct['NETWORK_UP'] = ct['network'].astype(str).str.upper()
    focus = ['KBS','MBC','TVN','NETFLIX','SBS']
    fig3 = px.line(ct[ct['NETWORK_UP'].isin(focus)], x='start airing', y='count', color='network',
                   log_y=True, title="ì—°ë„ë³„ ì£¼ìš” í”Œë«í¼ ì‘í’ˆ ìˆ˜")
    st.plotly_chart(fig3, use_container_width=True)

    p = (ct.pivot_table(index='start airing', columns='NETWORK_UP', values='count', aggfunc='sum')
           .fillna(0).astype(int))
    years = sorted(p.index)
    insights = []

    if 'NETFLIX' in p.columns:
        s = p['NETFLIX']; nz = s[s > 0]
        if not nz.empty:
            first_year = int(nz.index.min())
            max_year, max_val = int(s.idxmax()), int(s.max())
            txt = f"- **ë„·í”Œë¦­ìŠ¤(OTT)ì˜ ê¸‰ì„±ì¥**: {first_year}ë…„ ì´í›„ ë¹ ë¥´ê²Œ ì¦ê°€, **{max_year}ë…„ {max_val}í¸** ìµœê³ ì¹˜."
            insights.append(txt)

    import numpy as np
    down_ter = []
    for b in ['KBS','MBC','SBS']:
        if b in p.columns and len(years) >= 2:
            slope = np.polyfit(years, p[b].reindex(years, fill_value=0), 1)[0]
            if slope < 0: down_ter.append(b)
    if down_ter:
        insights.append(f"- **ì§€ìƒíŒŒ ê°ì†Œ ì¶”ì„¸**: {' / '.join(down_ter)} ì „ë°˜ì  í•˜ë½.")

    st.markdown("**ì¸ì‚¬ì´íŠ¸**\n" + "\n".join(insights))

    # ===== ì¥ë¥´ ê°œìˆ˜ë³„ ë°°ìš° í‰ê·  í‰ì  (ë°°ìš° ë‹¨ìœ„) =====
    st.subheader("ì¥ë¥´ ê°œìˆ˜ë³„ í‰ê·  í‰ì  (ë°°ìš° ë‹¨ìœ„, 1~2 / 3~4 / 5~6 / 7+)")
    actor_col = 'ë°°ìš°ëª…' if 'ë°°ìš°ëª…' in raw_df.columns else ('actor' if 'actor' in raw_df.columns else None)
    if actor_col is None:
        st.info("ë°°ìš° ì‹ë³„ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´(ë°°ìš°ëª…/actor) ì´ ì„¹ì…˜ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        gdf = (
            pd.DataFrame({actor_col: raw_df[actor_col], 'genres': raw_df['genres'].apply(clean_cell_colab)})
            .explode('genres').dropna(subset=[actor_col,'genres'])
        )
        genre_cnt = gdf.groupby(actor_col)['genres'].nunique().rename('ì¥ë¥´ê°œìˆ˜')
        actor_mean = (raw_df.groupby(actor_col, as_index=False)['score']
                      .mean().rename(columns={'score':'ë°°ìš°í‰ê· ì ìˆ˜'}))
        df_actor = actor_mean.merge(genre_cnt.reset_index(), on=actor_col, how='left')
        df_actor['ì¥ë¥´ê°œìˆ˜'] = df_actor['ì¥ë¥´ê°œìˆ˜'].fillna(0).astype(int)
        df_actor = df_actor[df_actor['ì¥ë¥´ê°œìˆ˜'] > 0].copy()

        def bucket(n: int) -> str:
            if n <= 2:  return '1~2ê°œ'
            if n <= 4:  return '3~4ê°œ'
            if n <= 6:  return '5~6ê°œ'
            return '7ê°œ ì´ìƒ'

        df_actor['ì¥ë¥´ê°œìˆ˜êµ¬ê°„'] = pd.Categorical(
            df_actor['ì¥ë¥´ê°œìˆ˜'].apply(bucket),
            categories=['1~2ê°œ','3~4ê°œ','5~6ê°œ','7ê°œ ì´ìƒ'],
            ordered=True
        )

        fig_box = px.box(
            df_actor, x='ì¥ë¥´ê°œìˆ˜êµ¬ê°„', y='ë°°ìš°í‰ê· ì ìˆ˜',
            category_orders={'ì¥ë¥´ê°œìˆ˜êµ¬ê°„': ['1~2ê°œ','3~4ê°œ','5~6ê°œ','7ê°œ ì´ìƒ']},
            title="ì¥ë¥´ ê°œìˆ˜ë³„ ë°°ìš° í‰ê·  ì ìˆ˜ ë¶„í¬"
        )
        st.plotly_chart(fig_box, use_container_width=True)

        stats = (df_actor.groupby('ì¥ë¥´ê°œìˆ˜êµ¬ê°„')['ë°°ìš°í‰ê· ì ìˆ˜']
                 .agg(í‰ê· ='mean', ì¤‘ì•™ê°’='median', í‘œë³¸ìˆ˜='count')
                 .reindex(['1~2ê°œ','3~4ê°œ','5~6ê°œ','7ê°œ ì´ìƒ']).dropna(how='all').round(3))
        if not stats.empty and stats['í‘œë³¸ìˆ˜'].sum() > 0:
            st.markdown("**ìš”ì•½ í†µê³„(ë°°ìš° ë‹¨ìœ„)**")
            try: st.markdown(stats.to_markdown())
            except Exception: st.dataframe(stats.reset_index(), use_container_width=True)

    # ===== ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ =====
    st.subheader("ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ")
    main_roles = raw_df[raw_df['role']=='ì£¼ì—°'].copy()
    main_roles['ê²°í˜¼ìƒíƒœ'] = main_roles['married'].apply(lambda x: 'ë¯¸í˜¼' if x=='ë¯¸í˜¼' else 'ë¯¸í˜¼ ì™¸')
    avg_scores_by_marriage = main_roles.groupby('ê²°í˜¼ìƒíƒœ')['score'].mean()
    fig, ax = plt.subplots(figsize=(3.5, 3.5))
    bars = ax.bar(avg_scores_by_marriage.index, avg_scores_by_marriage.values, color=['mediumseagreen','gray'])
    for b in bars:
        yv = b.get_height()
        ax.text(b.get_x()+b.get_width()/2, yv+0.005, f'{yv:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
    ax.set_title('ì£¼ì—° ë°°ìš° ê²°í˜¼ ìƒíƒœë³„ í‰ê·  ì ìˆ˜ ë¹„êµ'); ax.set_ylabel('í‰ê·  ì ìˆ˜'); ax.set_xlabel('ê²°í˜¼ ìƒíƒœ')
    ax.set_ylim(min(avg_scores_by_marriage.values)-0.05, max(avg_scores_by_marriage.values)+0.05)
    ax.grid(axis='y', linestyle='--', alpha=0.5)
    st.pyplot(fig)

    # ===== ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜ =====
    st.subheader("ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜")
    dfg = raw_df.copy()
    dfg['genres'] = dfg['genres'].apply(clean_cell_colab)
    dfg = dfg.explode('genres').dropna(subset=['genres','score'])
    g_score = dfg.groupby('genres')['score'].mean().round(3)
    g_count = dfg['genres'].value_counts()
    gdf = pd.DataFrame({'í‰ê·  ì ìˆ˜': g_score, 'ì‘í’ˆ ìˆ˜': g_count}).reset_index().rename(columns={'index':'ì¥ë¥´','genres':'ì¥ë¥´'})
    gdf = gdf.sort_values('ì‘í’ˆ ìˆ˜', ascending=False).reset_index(drop=True)
    fig, ax1 = plt.subplots(figsize=(12,6))
    bars = ax1.bar(range(len(gdf)), gdf['ì‘í’ˆ ìˆ˜'], color='lightgray')
    ax1.set_ylabel('ì‘í’ˆ ìˆ˜'); ax1.set_xticks(range(len(gdf))); ax1.set_xticklabels(gdf['ì¥ë¥´'], rotation=45, ha='right')
    for i, r in enumerate(bars):
        h = r.get_height()
        ax1.text(i, h+max(2, h*0.01), f'{int(h)}', ha='center', va='bottom', fontsize=10, fontweight='bold', color='#444')
    ax2 = ax1.twinx()
    ax2.plot(range(len(gdf)), gdf['í‰ê·  ì ìˆ˜'], marker='o', linewidth=2)
    ax2.set_ylabel('í‰ê·  ì ìˆ˜'); ax2.set_ylim(gdf['í‰ê·  ì ìˆ˜'].min()-0.1, gdf['í‰ê·  ì ìˆ˜'].max()+0.1)
    for i, v in enumerate(gdf['í‰ê·  ì ìˆ˜']):
        ax2.text(i, v+0.01, f'{v:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
    plt.title('ì¥ë¥´ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜'); ax1.set_xlabel('ì¥ë¥´'); ax1.grid(axis='y', linestyle='--', alpha=0.5)
    st.pyplot(fig)

    # ===== ìš”ì¼/ë…„ë„ ë“± (ìš”ì•½) =====
    st.subheader("ë°©ì˜ ìš”ì¼ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜ (ì›”â†’ì¼)")
    dfe = raw_df.copy(); dfe['day'] = dfe['day'].apply(clean_cell_colab)
    dfe = dfe.explode('day').dropna(subset=['day','score']).copy()
    dfe['day'] = dfe['day'].astype(str).str.strip().str.lower()
    ordered = ['monday','tuesday','wednesday','thursday','friday','saturday','sunday']
    day_ko = {'monday':'ì›”','tuesday':'í™”','wednesday':'ìˆ˜','thursday':'ëª©','friday':'ê¸ˆ','saturday':'í† ','sunday':'ì¼'}
    mean_by = dfe.groupby('day')['score'].mean().reindex(ordered)
    cnt_by = dfe['day'].value_counts().reindex(ordered).fillna(0).astype(int)
    fig, ax1 = plt.subplots(figsize=(12,6))
    bars = ax1.bar(ordered, cnt_by.values, alpha=0.3, color='tab:gray')
    ax1.set_ylabel('ì‘í’ˆ ìˆ˜', color='tab:gray')
    for b in bars:
        h = b.get_height(); ax1.text(b.get_x()+b.get_width()/2, h+0.5, f'{int(h)}', ha='center', va='bottom', fontsize=9)
    ax2 = ax1.twinx(); ax2.plot(ordered, mean_by.values, marker='o')
    ax2.set_ylabel('í‰ê·  ì ìˆ˜')
    if mean_by.notna().any(): ax2.set_ylim(mean_by.min()-0.05, mean_by.max()+0.05)
    for x, yv in zip(ordered, mean_by.values):
        if pd.notna(yv): ax2.text(x, yv+0.005, f'{yv:.3f}', fontsize=9, ha='center')
    ax1.set_xticks(ordered); ax1.set_xticklabels([day_ko[d] for d in ordered])
    plt.title('ë°©ì˜ ìš”ì¼ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜'); plt.tight_layout(); st.pyplot(fig, use_container_width=False)

    # ë°©ì˜ë…„ë„
    st.subheader("ë°©ì˜ë…„ë„ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜")
    dfe = raw_df.copy()
    dfe['start airing'] = pd.to_numeric(dfe['start airing'], errors='coerce')
    dfe['score'] = pd.to_numeric(dfe['score'], errors='coerce')
    dfe = dfe.dropna(subset=['start airing','score']).copy()
    dfe['start airing'] = dfe['start airing'].astype(int)
    mean_score_by_year = dfe.groupby('start airing')['score'].mean().round(3)
    count_by_year = dfe['start airing'].value_counts()
    years = sorted(set(mean_score_by_year.index) | set(count_by_year.index))
    mean_s = mean_score_by_year.reindex(years); count_s = count_by_year.reindex(years, fill_value=0)
    fig, ax1 = plt.subplots(figsize=(12, 6))
    color_bar = 'tab:gray'; ax1.set_xlabel('ë°©ì˜ë…„ë„'); ax1.set_ylabel('ì‘í’ˆ ìˆ˜', color=color_bar)
    bars = ax1.bar(years, count_s.values, alpha=0.3, color=color_bar, width=0.6)
    for bar in bars:
        h = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2, h + max(0.5, h*0.02), f'{int(h)}', ha='center', va='bottom', fontsize=9)
    ax2 = ax1.twinx(); ax2.set_ylabel('í‰ê·  ì ìˆ˜')
    ax2.plot(years, mean_s.values, marker='o')
    if mean_s.notna().any(): ax2.set_ylim(mean_s.min() - 0.05, mean_s.max() + 0.05)
    for x, y in zip(years, mean_s.values):
        if pd.notna(y): ax2.text(x, y + 0.01, f'{y:.3f}', fontsize=9, ha='center')
    plt.title('ë°©ì˜ë…„ë„ë³„ ì‘í’ˆ ìˆ˜ ë° í‰ê·  ì ìˆ˜'); plt.tight_layout(); st.pyplot(fig, use_container_width=False)

def page_filter_live():
    st.header("ì‹¤ì‹œê°„ í•„í„°")
    smin,smax = float(pd.to_numeric(raw_df['score'], errors='coerce').min()), float(pd.to_numeric(raw_df['score'], errors='coerce').max())
    sfilter = st.slider("ìµœì†Œ í‰ì ", smin,smax,smin)
    y_min = int(pd.to_numeric(raw_df['start airing'], errors='coerce').min())
    y_max = int(pd.to_numeric(raw_df['start airing'], errors='coerce').max())
    yfilter = st.slider("ë°©ì˜ë…„ë„ ë²”ìœ„", y_min, y_max, (y_min, y_max))
    filt = raw_df[(pd.to_numeric(raw_df['score'], errors='coerce')>=sfilter) &
                  pd.to_numeric(raw_df['start airing'], errors='coerce').between(*yfilter)]
    st.dataframe(filt.head(20), use_container_width=True)

def page_allview():
    st.header("ì›ë³¸ ì „ì²´ë³´ê¸°")
    st.dataframe(raw_df, use_container_width=True)

def page_tuning():
    st.header("GridSearchCV íŠœë‹")
    if "split_colab" not in st.session_state or st.session_state.get("split_key") != float(test_size):
        X_train, X_test, y_train, y_test = train_test_split(
            X_colab_base, y_all, test_size=test_size, random_state=SEED, shuffle=True
        )
        st.session_state["split_colab"] = (X_train, X_test, y_train, y_test)
        st.session_state["split_key"] = float(test_size)
    X_train, X_test, y_train, y_test = st.session_state["split_colab"]

    scoring = st.selectbox("ìŠ¤ì½”ì–´ë§", ["neg_root_mean_squared_error", "r2"], index=0)
    cv = st.number_input("CV í´ë“œ ìˆ˜", 3, 10, 5, 1)
    cv_shuffle = st.checkbox("CV ì…”í”Œ(shuffle)", value=False)

    def render_param_selector(label, options):
        display_options, to_py = [], {}
        for v in options:
            if v is None: s="(None)"; to_py[s]=None
            else:
                s = str(int(v)) if isinstance(v, float) and v.is_integer() else str(v)
                to_py[s] = v
            display_options.append(s)
        sel = st.multiselect(f"{label}", display_options, default=display_options, key=f"sel_{label}")
        extra = st.text_input(f"{label} ì¶”ê°€ê°’(ì½¤ë§ˆ, ì˜ˆ: 50,75,100 ë˜ëŠ” None)", value="", key=f"extra_{label}")
        chosen = [to_py[s] for s in sel]
        if extra.strip():
            for tok in extra.split(","):
                t = tok.strip()
                if not t: continue
                if t.lower()=="none": val=None
                else:
                    try: val=int(t)
                    except:
                        try: val=float(t)
                        except: val=t
                chosen.append(val)
        uniq=[]
        for v in chosen:
            if v not in uniq: uniq.append(v)
        return uniq

    model_zoo = {
        "KNN": ("nonsparse", KNeighborsRegressor()),
        "Linear Regression (Poly)": ("nonsparse", LinearRegression()),
        "Ridge": ("nonsparse", Ridge()),
        "Lasso": ("nonsparse", Lasso()),
        "ElasticNet": ("nonsparse", ElasticNet(max_iter=10000)),
        "SGDRegressor": ("nonsparse", SGDRegressor(max_iter=10000, random_state=SEED)),
        "SVR": ("nonsparse", SVR()),
        "Decision Tree": ("tree", DecisionTreeRegressor(random_state=SEED)),
        "Random Forest": ("tree", RandomForestRegressor(random_state=SEED)),
    }
    if 'XGBRegressor' in globals() and XGB_AVAILABLE:
        model_zoo["XGBRegressor"] = ("tree", XGBRegressor(
            random_state=SEED, objective="reg:squarederror", n_jobs=-1, tree_method="hist"
        ))

    default_param_grids = {
        "KNN": {"poly__degree":[1,2,3], "knn__n_neighbors":[3,4,5,6,7,8,9,10]},
        "Linear Regression (Poly)": {"poly__degree":[1,2,3]},
        "Ridge": {"poly__degree":[1,2,3], "model__alpha":[0.001,0.01,0.1,1,10,100,1000]},
        "Lasso": {"poly__degree":[1,2,3], "model__alpha":[0.001,0.01,0.1,1,10,100,1000]},
        "ElasticNet": {"poly__degree":[1,2,3], "model__alpha":[0.001,0.01,0.1,1,10,100,1000], "model__l1_ratio":[0.1,0.5,0.9]},
        "SGDRegressor": {"poly__degree":[1,2,3], "model__learning_rate":["constant","invscaling","adaptive"]},
        "SVR": {"model__kernel":["poly","rbf","sigmoid"], "model__degree":[1,2,3]},
        "Decision Tree": {"model__max_depth":[10,15,20,25,30], "model__min_samples_split":[5,6,7,8,9,10], "model__min_samples_leaf":[2,3,4,5], "model__max_leaf_nodes":[None,10,20,30]},
        "Random Forest": {"model__n_estimators":[100,200,300], "model__min_samples_split":[5,6,7,8,9,10], "model__max_depth":[5,10,15,20,25,30]},
    }
    if "XGBRegressor" in model_zoo:
        default_param_grids["XGBRegressor"] = {
            "model__n_estimators":[200,400],
            "model__max_depth":[3,5,7],
            "model__learning_rate":[0.03,0.1,0.3],
            "model__subsample":[0.8,1.0],
            "model__colsample_bytree":[0.8,1.0],
        }

    model_name = st.selectbox("íŠœë‹í•  ëª¨ë¸ ì„ íƒ", list(model_zoo.keys()), index=0)
    kind, estimator = model_zoo[model_name]
    pipe = make_pipeline(model_name, kind, estimator)

    st.markdown("**í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„ íƒ**")
    base_grid = default_param_grids.get(model_name, {})
    user_grid = {}
    for param_key, default_vals in base_grid.items():
        user_vals = render_param_selector(param_key, default_vals)
        user_grid[param_key] = user_vals if len(user_vals) > 0 else default_vals

    with st.expander("ì„ íƒí•œ íŒŒë¼ë¯¸í„° í™•ì¸"):
        st.write(user_grid)

    if st.button("GridSearch ì‹¤í–‰"):
        cv_obj = KFold(n_splits=int(cv), shuffle=bool(cv_shuffle), random_state=SEED) if cv_shuffle else int(cv)
        gs = GridSearchCV(
            estimator=pipe, param_grid=user_grid, cv=cv_obj,
            scoring=scoring, n_jobs=-1, refit=True, return_train_score=True
        )
        with st.spinner("GridSearchCV ì‹¤í–‰ ì¤‘..."):
            gs.fit(X_train, y_train)

        st.subheader("ë² ìŠ¤íŠ¸ ê²°ê³¼")
        st.write("Best Params:", gs.best_params_)
        if scoring == "neg_root_mean_squared_error":
            st.write("Best CV RMSE (ìŒìˆ˜):", gs.best_score_)
        else:
            st.write(f"Best CV {scoring}:", gs.best_score_)

        y_pred_tr = gs.predict(X_train); y_pred_te = gs.predict(X_test)
        st.write("Train RMSE:", rmse(y_train, y_pred_tr))
        st.write("Test RMSE:", rmse(y_test, y_pred_te))
        st.write("Train RÂ² Score:", r2_score(y_train, y_pred_tr))
        st.write("Test RÂ² Score:", r2_score(y_test, y_pred_te))

        st.session_state["best_estimator"] = gs.best_estimator_
        st.session_state["best_params"] = gs.best_params_
        st.session_state["best_name"] = model_name
        st.session_state["best_cv_score"] = gs.best_score_
        st.session_state["best_scoring"] = scoring
        st.session_state["best_split_key"] = st.session_state.get("split_key")

        cvres = pd.DataFrame(gs.cv_results_)
        safe_cols = [c for c in ["rank_test_score","mean_test_score","std_test_score","mean_train_score","std_train_score","params"] if c in cvres.columns]
        sorted_cvres = cvres.loc[:, safe_cols].sort_values("rank_test_score").reset_index(drop=True)
        st.dataframe(sorted_cvres, use_container_width=True)

    if model_name == "XGBRegressor" and not XGB_AVAILABLE:
        st.warning("xgboostê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. requirements.txtì— `xgboost`ë¥¼ ì¶”ê°€í•˜ê³  ì¬ë°°í¬í•´ ì£¼ì„¸ìš”.")

def page_ml():
    st.header("ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë§")
    if "split_colab" not in st.session_state or st.session_state.get("split_key") != float(test_size):
        X_train, X_test, y_train, y_test = train_test_split(
            X_colab_base, y_all, test_size=test_size, random_state=SEED, shuffle=True
        )
        st.session_state["split_colab"] = (X_train, X_test, y_train, y_test)
        st.session_state["split_key"] = float(test_size)
    X_train, X_test, y_train, y_test = st.session_state["split_colab"]

    if "best_estimator" in st.session_state:
        model = st.session_state["best_estimator"]
        st.caption(f"í˜„ì¬ ëª¨ë¸: GridSearch ë² ìŠ¤íŠ¸ ëª¨ë¸ ì‚¬ìš© ({st.session_state.get('best_name')})")
        if st.session_state.get("best_split_key") != st.session_state.get("split_key"):
            st.warning("ì£¼ì˜: ë² ìŠ¤íŠ¸ ëª¨ë¸ì€ ì´ì „ ë¶„í• ë¡œ í•™ìŠµë¨. ìƒˆ ë¶„í• ë¡œ ë‹¤ì‹œ íŠœë‹í•´ ì£¼ì„¸ìš”.", icon="âš ï¸")
    else:
        model = Pipeline([('preprocessor', preprocessor),
                          ('model', RandomForestRegressor(random_state=SEED))])
        model.fit(X_train, y_train)
        st.caption("í˜„ì¬ ëª¨ë¸: ê¸°ë³¸ RandomForest (ë¯¸íŠœë‹)")

    y_pred_tr = model.predict(X_train); y_pred_te = model.predict(X_test)
    st.metric("Train RÂ²", f"{r2_score(y_train, y_pred_tr):.3f}")
    st.metric("Test  RÂ²", f"{r2_score(y_test,  y_pred_te):.3f}")
    st.metric("Train RMSE", f"{rmse(y_train, y_pred_tr):.3f}")
    st.metric("Test  RMSE", f"{rmse(y_test,  y_pred_te):.3f}")

    if "best_params" in st.session_state:
        with st.expander("ë² ìŠ¤íŠ¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë³´ê¸°"):
            st.json(st.session_state["best_params"])

def page_predict():
    # === ë„¤ê°€ ì˜¬ë¦° 'ì˜ˆì¸¡ + What-if' ìµœì‹  ë¸”ë¡ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© ===
    st.header("í‰ì  ì˜ˆì¸¡")
    # ì•„ë˜ë¶€í„°ëŠ” ì´ì „ íƒ­ ì½”ë“œì˜ ì˜ˆì¸¡ ì„¹ì…˜ì„ ê·¸ëŒ€ë¡œ ë³µë¶™
    # (ê¸¸ì–´ì„œ ì—¬ê¸°ì„œëŠ” ìƒëµí•  ìˆ˜ ì—†ìœ¼ë‹ˆ, ë„¤ ì§ì „ ë²„ì „ì˜ with tabs[7]: ë¸”ë¡ ë‚´ë¶€ ë‚´ìš©ì„ ê·¸ëŒ€ë¡œ ë„£ì–´ì£¼ì„¸ìš”)
    st.info("ì—¬ê¸°ì— ê¸°ì¡´ ì˜ˆì¸¡ ì„¹ì…˜ ì „ì²´ ì½”ë“œë¥¼ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ì—ˆìŠµë‹ˆë‹¤. (í˜„ì¬ íŒŒì¼ì—ì„œëŠ” ìƒëµ í‘œì‹œë§Œ í–ˆìŠµë‹ˆë‹¤)")

# ===== ë¼ìš°íŒ…(ì„ íƒì— ë”°ë¼ í˜ì´ì§€ í•¨ìˆ˜ í˜¸ì¶œ) =====
PAGES = {
    "overview": page_overview,
    "basic":    page_basic_stats,
    "dist":     page_dist_cross,
    "filter":   page_filter_live,
    "all":      page_allview,
    "tuning":   page_tuning,
    "ml":       page_ml,
    "predict":  page_predict,
}
PAGES.get(st.session_state["nav"], page_overview)()
